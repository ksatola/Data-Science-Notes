{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "From: https://github.com/ksatola\n",
    "Version: 0.0.1\n",
    "\n",
    "TODOs\n",
    "1. \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Ex - Regression\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "Feature Selection (this Notebook):\n",
    "- [Regression Dataset](#)\n",
    "- XXXX dokonczyc\n",
    "- [Introduction](#intro)\n",
    "    - Cross Validation\n",
    "    - Methods\n",
    "- [Feature Selection Checklist](#check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect with underlying Python code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import (\n",
    "    get_dataset\n",
    ")\n",
    "\n",
    "from feature_selection import (\n",
    "    select_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Dataset\n",
    "The [make_regression()](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html) function from the scikit-learn library can be used to define a dataset. It provides control over the number of samples, number of input features, and, importantly, the number of relevant and redundant input features. This is critical as we specifically desire a dataset that we know has some redundant input features.\n",
    "\n",
    "We will define a dataset with 1,000 samples, each with 100 input features where 10 are informative and the remaining 90 are redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and summarize the dataset\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.308937</td>\n",
       "      <td>-1.358117</td>\n",
       "      <td>1.799673</td>\n",
       "      <td>0.370344</td>\n",
       "      <td>-1.089044</td>\n",
       "      <td>-0.611431</td>\n",
       "      <td>-0.335119</td>\n",
       "      <td>1.147323</td>\n",
       "      <td>-1.054796</td>\n",
       "      <td>0.139363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.450311</td>\n",
       "      <td>-0.015725</td>\n",
       "      <td>-0.080910</td>\n",
       "      <td>-0.809523</td>\n",
       "      <td>-0.615246</td>\n",
       "      <td>0.251029</td>\n",
       "      <td>-0.161305</td>\n",
       "      <td>-0.552200</td>\n",
       "      <td>-1.508041</td>\n",
       "      <td>0.149237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.714677</td>\n",
       "      <td>-0.911399</td>\n",
       "      <td>0.704543</td>\n",
       "      <td>0.072666</td>\n",
       "      <td>-0.146416</td>\n",
       "      <td>-1.417644</td>\n",
       "      <td>-0.267344</td>\n",
       "      <td>0.963182</td>\n",
       "      <td>1.159643</td>\n",
       "      <td>-0.782204</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002065</td>\n",
       "      <td>-1.594992</td>\n",
       "      <td>1.299482</td>\n",
       "      <td>0.285062</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.049349</td>\n",
       "      <td>1.239483</td>\n",
       "      <td>-0.770401</td>\n",
       "      <td>0.497540</td>\n",
       "      <td>0.836287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.414273</td>\n",
       "      <td>0.270416</td>\n",
       "      <td>-1.890207</td>\n",
       "      <td>-0.984467</td>\n",
       "      <td>-0.509132</td>\n",
       "      <td>-0.236473</td>\n",
       "      <td>0.924821</td>\n",
       "      <td>-1.554528</td>\n",
       "      <td>0.220635</td>\n",
       "      <td>-1.079696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240047</td>\n",
       "      <td>1.455053</td>\n",
       "      <td>-0.853952</td>\n",
       "      <td>0.227808</td>\n",
       "      <td>-1.869735</td>\n",
       "      <td>0.606788</td>\n",
       "      <td>-0.503986</td>\n",
       "      <td>0.434974</td>\n",
       "      <td>0.967623</td>\n",
       "      <td>1.107183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.537630</td>\n",
       "      <td>-0.936710</td>\n",
       "      <td>0.922793</td>\n",
       "      <td>-0.003897</td>\n",
       "      <td>-1.335670</td>\n",
       "      <td>-0.665940</td>\n",
       "      <td>0.716759</td>\n",
       "      <td>-0.155484</td>\n",
       "      <td>1.408668</td>\n",
       "      <td>2.234314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171679</td>\n",
       "      <td>-2.075227</td>\n",
       "      <td>0.357591</td>\n",
       "      <td>-0.653531</td>\n",
       "      <td>-0.516247</td>\n",
       "      <td>-1.373571</td>\n",
       "      <td>0.145010</td>\n",
       "      <td>1.631103</td>\n",
       "      <td>-1.623318</td>\n",
       "      <td>1.773253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.484542</td>\n",
       "      <td>1.470649</td>\n",
       "      <td>1.364323</td>\n",
       "      <td>-0.467492</td>\n",
       "      <td>1.580360</td>\n",
       "      <td>-0.009018</td>\n",
       "      <td>0.412203</td>\n",
       "      <td>0.587010</td>\n",
       "      <td>-0.461107</td>\n",
       "      <td>-0.079273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.292875</td>\n",
       "      <td>-1.347707</td>\n",
       "      <td>-0.473457</td>\n",
       "      <td>-0.345626</td>\n",
       "      <td>-0.040660</td>\n",
       "      <td>-1.085091</td>\n",
       "      <td>0.174213</td>\n",
       "      <td>-0.919603</td>\n",
       "      <td>-0.324808</td>\n",
       "      <td>0.019620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.308937 -1.358117  1.799673  0.370344 -1.089044 -0.611431 -0.335119   \n",
       "1 -0.714677 -0.911399  0.704543  0.072666 -0.146416 -1.417644 -0.267344   \n",
       "2 -2.414273  0.270416 -1.890207 -0.984467 -0.509132 -0.236473  0.924821   \n",
       "3  1.537630 -0.936710  0.922793 -0.003897 -1.335670 -0.665940  0.716759   \n",
       "4 -0.484542  1.470649  1.364323 -0.467492  1.580360 -0.009018  0.412203   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  1.147323 -1.054796  0.139363  ... -0.450311 -0.015725 -0.080910 -0.809523   \n",
       "1  0.963182  1.159643 -0.782204  ...  1.002065 -1.594992  1.299482  0.285062   \n",
       "2 -1.554528  0.220635 -1.079696  ... -0.240047  1.455053 -0.853952  0.227808   \n",
       "3 -0.155484  1.408668  2.234314  ...  0.171679 -2.075227  0.357591 -0.653531   \n",
       "4  0.587010 -0.461107 -0.079273  ... -0.292875 -1.347707 -0.473457 -0.345626   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0 -0.615246  0.251029 -0.161305 -0.552200 -1.508041  0.149237  \n",
       "1  0.109400  0.049349  1.239483 -0.770401  0.497540  0.836287  \n",
       "2 -1.869735  0.606788 -0.503986  0.434974  0.967623  1.107183  \n",
       "3 -0.516247 -1.373571  0.145010  1.631103 -1.623318  1.773253  \n",
       "4 -0.040660 -1.085091  0.174213 -0.919603 -0.324808  0.019620  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.DataFrame(X)#, columns = ['Column_A','Column_B','Column_C'])\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (670, 100) (670,)\n",
      "Test (330, 100) (330,)\n"
     ]
    }
   ],
   "source": [
    "# Summarize\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Feature Selection\n",
    "\n",
    "Low variance:\n",
    "- **Remove features with low variance**\n",
    "\n",
    "Univariate feature selection:\n",
    "- **Correlation Feature Selection:** Correlation is a measure of how two variables change together. Perhaps the most common correlation measure is Pearson’s correlation that assumes a Gaussian distribution to each variable and reports on their linear relationship.\n",
    "- **Mutual Information Feature Selection:** Mutual information is calculated between two variables and measures the reduction in uncertainty for one variable given a known value of the other variable.\n",
    "\n",
    "Recursive feature elimination:\n",
    "- XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove features with low variance\n",
    "VarianceThreshold is a simple baseline approach to feature selection. It removes all features whose variance doesn’t meet some threshold. By default, it removes all zero-variance features, i.e. features that have the same value in all samples.\n",
    "\n",
    "As an example, suppose that we have a dataset with boolean features, and we want to remove all features that are either one or zero (on or off) in more than 80% of the samples. Boolean features are Bernoulli random variables, and the variance of such variables is given by\n",
    "```\n",
    "Var[X] = p(1-p)\n",
    "```\n",
    "so we can select using the threshold .8 * (1 - .8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15999999999999998"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".8 * (1 - .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "X1 = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just make a convenience function; this one wraps the VarianceThreshold\n",
    "# transformer but you can pass it a pandas dataframe and get one in return\n",
    "# https://stackoverflow.com/questions/29298973/removing-features-with-low-variance-using-scikit-learn\n",
    "\n",
    "def get_low_variance_columns(dframe=None, columns=None,\n",
    "                             skip_columns=None, thresh=0.0,\n",
    "                             autoremove=False):\n",
    "    \"\"\"\n",
    "    Wrapper for sklearn VarianceThreshold for use on pandas dataframes.\n",
    "    \"\"\"\n",
    "    print(\"Finding low-variance features.\")\n",
    "    try:\n",
    "        # get list of all the original df columns\n",
    "        all_columns = dframe.columns\n",
    "\n",
    "        # remove `skip_columns`\n",
    "        remaining_columns = all_columns.drop(skip_columns)\n",
    "\n",
    "        # get length of new index\n",
    "        max_index = len(remaining_columns) - 1\n",
    "\n",
    "        # get indices for `skip_columns`\n",
    "        skipped_idx = [all_columns.get_loc(column)\n",
    "                       for column\n",
    "                       in skip_columns]\n",
    "\n",
    "        # adjust insert location by the number of columns removed\n",
    "        # (for non-zero insertion locations) to keep relative\n",
    "        # locations intact\n",
    "        for idx, item in enumerate(skipped_idx):\n",
    "            if item > max_index:\n",
    "                diff = item - max_index\n",
    "                skipped_idx[idx] -= diff\n",
    "            if item == max_index:\n",
    "                diff = item - len(skip_columns)\n",
    "                skipped_idx[idx] -= diff\n",
    "            if idx == 0:\n",
    "                skipped_idx[idx] = item\n",
    "\n",
    "        # get values of `skip_columns`\n",
    "        skipped_values = dframe.iloc[:, skipped_idx].values\n",
    "\n",
    "        # get dataframe values\n",
    "        X = dframe.loc[:, remaining_columns].values\n",
    "\n",
    "        # instantiate VarianceThreshold object\n",
    "        vt = VarianceThreshold(threshold=thresh)\n",
    "\n",
    "        # fit vt to data\n",
    "        vt.fit(X)\n",
    "\n",
    "        # get the indices of the features that are being kept\n",
    "        feature_indices = vt.get_support(indices=True)\n",
    "\n",
    "        # remove low-variance columns from index\n",
    "        feature_names = [remaining_columns[idx]\n",
    "                         for idx, _\n",
    "                         in enumerate(remaining_columns)\n",
    "                         if idx\n",
    "                         in feature_indices]\n",
    "\n",
    "        # get the columns to be removed\n",
    "        removed_features = list(np.setdiff1d(remaining_columns,\n",
    "                                             feature_names))\n",
    "        print(\"Found {0} low-variance columns.\"\n",
    "              .format(len(removed_features)))\n",
    "\n",
    "        # remove the columns\n",
    "        if autoremove:\n",
    "            print(\"Removing low-variance features.\")\n",
    "            # remove the low-variance columns\n",
    "            X_removed = vt.transform(X)\n",
    "\n",
    "            print(\"Reassembling the dataframe (with low-variance \"\n",
    "                  \"features removed).\")\n",
    "            # re-assemble the dataframe\n",
    "            dframe = pd.DataFrame(data=X_removed,\n",
    "                                  columns=feature_names)\n",
    "\n",
    "            # add back the `skip_columns`\n",
    "            for idx, index in enumerate(skipped_idx):\n",
    "                dframe.insert(loc=index,\n",
    "                              column=skip_columns[idx],\n",
    "                              value=skipped_values[:, idx])\n",
    "            print(\"Succesfully removed low-variance columns.\")\n",
    "\n",
    "        # do not remove columns\n",
    "        else:\n",
    "            print(\"No changes have been made to the dataframe.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Could not remove low-variance features. Something \"\n",
    "              \"went wrong.\")\n",
    "        pass\n",
    "\n",
    "    return dframe, removed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.871971</td>\n",
       "      <td>-0.291231</td>\n",
       "      <td>0.902389</td>\n",
       "      <td>-0.869972</td>\n",
       "      <td>0.979617</td>\n",
       "      <td>-1.481788</td>\n",
       "      <td>0.074030</td>\n",
       "      <td>0.379316</td>\n",
       "      <td>-0.656935</td>\n",
       "      <td>0.317963</td>\n",
       "      <td>...</td>\n",
       "      <td>1.245430</td>\n",
       "      <td>-0.723215</td>\n",
       "      <td>0.169526</td>\n",
       "      <td>0.487529</td>\n",
       "      <td>-0.248418</td>\n",
       "      <td>0.827471</td>\n",
       "      <td>-1.259159</td>\n",
       "      <td>1.355173</td>\n",
       "      <td>0.720103</td>\n",
       "      <td>1.332368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.220610</td>\n",
       "      <td>-0.123730</td>\n",
       "      <td>0.985174</td>\n",
       "      <td>-0.010736</td>\n",
       "      <td>-0.022537</td>\n",
       "      <td>0.313770</td>\n",
       "      <td>1.470754</td>\n",
       "      <td>-1.306269</td>\n",
       "      <td>1.581214</td>\n",
       "      <td>-0.981034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.889007</td>\n",
       "      <td>0.305280</td>\n",
       "      <td>-1.030287</td>\n",
       "      <td>0.346769</td>\n",
       "      <td>-0.924873</td>\n",
       "      <td>0.676581</td>\n",
       "      <td>0.577162</td>\n",
       "      <td>0.408939</td>\n",
       "      <td>-0.836799</td>\n",
       "      <td>0.786225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.494456</td>\n",
       "      <td>-0.553212</td>\n",
       "      <td>1.305315</td>\n",
       "      <td>-0.809376</td>\n",
       "      <td>1.467617</td>\n",
       "      <td>-0.681215</td>\n",
       "      <td>-0.771241</td>\n",
       "      <td>1.261611</td>\n",
       "      <td>-1.097849</td>\n",
       "      <td>0.712218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.671565</td>\n",
       "      <td>0.195052</td>\n",
       "      <td>0.960592</td>\n",
       "      <td>-0.799993</td>\n",
       "      <td>0.570993</td>\n",
       "      <td>0.056986</td>\n",
       "      <td>-0.286504</td>\n",
       "      <td>-1.681562</td>\n",
       "      <td>-0.305025</td>\n",
       "      <td>0.452569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.900339</td>\n",
       "      <td>-0.935345</td>\n",
       "      <td>-0.192279</td>\n",
       "      <td>1.289228</td>\n",
       "      <td>0.925454</td>\n",
       "      <td>-1.165921</td>\n",
       "      <td>-0.562240</td>\n",
       "      <td>0.950477</td>\n",
       "      <td>-1.316410</td>\n",
       "      <td>-0.259530</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.917765</td>\n",
       "      <td>0.817614</td>\n",
       "      <td>-0.730616</td>\n",
       "      <td>0.304676</td>\n",
       "      <td>-1.410802</td>\n",
       "      <td>-0.169603</td>\n",
       "      <td>-0.625380</td>\n",
       "      <td>-0.532919</td>\n",
       "      <td>-0.432969</td>\n",
       "      <td>-0.981493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033686</td>\n",
       "      <td>-2.041298</td>\n",
       "      <td>-2.634345</td>\n",
       "      <td>-1.545732</td>\n",
       "      <td>-0.604669</td>\n",
       "      <td>0.088849</td>\n",
       "      <td>-0.899741</td>\n",
       "      <td>-0.366217</td>\n",
       "      <td>0.601805</td>\n",
       "      <td>-0.240145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876640</td>\n",
       "      <td>-0.340806</td>\n",
       "      <td>-1.490400</td>\n",
       "      <td>0.068468</td>\n",
       "      <td>0.399456</td>\n",
       "      <td>-1.260501</td>\n",
       "      <td>-0.223374</td>\n",
       "      <td>0.137358</td>\n",
       "      <td>-0.881357</td>\n",
       "      <td>-0.672122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -1.871971 -0.291231  0.902389 -0.869972  0.979617 -1.481788  0.074030   \n",
       "1  1.220610 -0.123730  0.985174 -0.010736 -0.022537  0.313770  1.470754   \n",
       "2 -1.494456 -0.553212  1.305315 -0.809376  1.467617 -0.681215 -0.771241   \n",
       "3  0.900339 -0.935345 -0.192279  1.289228  0.925454 -1.165921 -0.562240   \n",
       "4  0.033686 -2.041298 -2.634345 -1.545732 -0.604669  0.088849 -0.899741   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  0.379316 -0.656935  0.317963  ...  1.245430 -0.723215  0.169526  0.487529   \n",
       "1 -1.306269  1.581214 -0.981034  ... -0.889007  0.305280 -1.030287  0.346769   \n",
       "2  1.261611 -1.097849  0.712218  ... -0.671565  0.195052  0.960592 -0.799993   \n",
       "3  0.950477 -1.316410 -0.259530  ... -0.917765  0.817614 -0.730616  0.304676   \n",
       "4 -0.366217  0.601805 -0.240145  ...  0.876640 -0.340806 -1.490400  0.068468   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0 -0.248418  0.827471 -1.259159  1.355173  0.720103  1.332368  \n",
       "1 -0.924873  0.676581  0.577162  0.408939 -0.836799  0.786225  \n",
       "2  0.570993  0.056986 -0.286504 -1.681562 -0.305025  0.452569  \n",
       "3 -1.410802 -0.169603 -0.625380 -0.532919 -0.432969 -0.981493  \n",
       "4  0.399456 -1.260501 -0.223374  0.137358 -0.881357 -0.672122  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_train)#, columns = ['Column_A','Column_B','Column_C'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding low-variance features.\n",
      "Found 0 low-variance columns.\n",
      "No changes have been made to the dataframe.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           0         1         2         3         4         5         6   \\\n",
       " 0   -1.871971 -0.291231  0.902389 -0.869972  0.979617 -1.481788  0.074030   \n",
       " 1    1.220610 -0.123730  0.985174 -0.010736 -0.022537  0.313770  1.470754   \n",
       " 2   -1.494456 -0.553212  1.305315 -0.809376  1.467617 -0.681215 -0.771241   \n",
       " 3    0.900339 -0.935345 -0.192279  1.289228  0.925454 -1.165921 -0.562240   \n",
       " 4    0.033686 -2.041298 -2.634345 -1.545732 -0.604669  0.088849 -0.899741   \n",
       " ..        ...       ...       ...       ...       ...       ...       ...   \n",
       " 665  1.204892  1.199805 -1.501007 -0.257250 -0.360571 -1.430155  0.434164   \n",
       " 666 -0.820832  1.533342 -0.504243 -0.060644 -0.669185  0.884871  0.601132   \n",
       " 667  0.746176  0.354306 -0.626249  0.981839  0.374672 -0.530459 -0.600365   \n",
       " 668 -0.498498  1.514459 -1.094931  0.188624 -0.936138 -1.431263 -1.003676   \n",
       " 669  0.452704  0.317291  0.645293 -0.766670  0.223224 -0.625196 -0.727168   \n",
       " \n",
       "            7         8         9   ...        90        91        92  \\\n",
       " 0    0.379316 -0.656935  0.317963  ...  1.245430 -0.723215  0.169526   \n",
       " 1   -1.306269  1.581214 -0.981034  ... -0.889007  0.305280 -1.030287   \n",
       " 2    1.261611 -1.097849  0.712218  ... -0.671565  0.195052  0.960592   \n",
       " 3    0.950477 -1.316410 -0.259530  ... -0.917765  0.817614 -0.730616   \n",
       " 4   -0.366217  0.601805 -0.240145  ...  0.876640 -0.340806 -1.490400   \n",
       " ..        ...       ...       ...  ...       ...       ...       ...   \n",
       " 665 -1.399627  0.464270  1.069494  ... -0.499199 -0.882016 -0.525783   \n",
       " 666  0.666608  1.243511 -0.312586  ...  1.665381 -0.195842  0.397679   \n",
       " 667  2.218231 -0.192415  0.216295  ...  0.118431  0.098028  1.721131   \n",
       " 668  0.085901 -1.720344  0.050197  ... -0.187065 -0.739818  0.618837   \n",
       " 669 -0.102701 -0.848309 -0.882189  ... -0.109093 -0.021059 -0.462445   \n",
       " \n",
       "            93        94        95        96        97        98        99  \n",
       " 0    0.487529 -0.248418  0.827471 -1.259159  1.355173  0.720103  1.332368  \n",
       " 1    0.346769 -0.924873  0.676581  0.577162  0.408939 -0.836799  0.786225  \n",
       " 2   -0.799993  0.570993  0.056986 -0.286504 -1.681562 -0.305025  0.452569  \n",
       " 3    0.304676 -1.410802 -0.169603 -0.625380 -0.532919 -0.432969 -0.981493  \n",
       " 4    0.068468  0.399456 -1.260501 -0.223374  0.137358 -0.881357 -0.672122  \n",
       " ..        ...       ...       ...       ...       ...       ...       ...  \n",
       " 665 -1.109296 -1.225551  0.649369  1.692752  0.323299 -0.711202 -0.284744  \n",
       " 666  0.585141  0.524915  0.561862  1.003468 -0.405893 -0.708565  1.101494  \n",
       " 667  0.839082 -0.076888  0.794086  0.133749 -1.202256 -1.054103  0.507903  \n",
       " 668  1.376664 -1.016521  0.249521 -1.163532 -0.975300  0.156993  0.806942  \n",
       " 669  1.102275  0.899203  0.981582  1.186722  0.574898  0.303635  0.478512  \n",
       " \n",
       " [670 rows x 100 columns],\n",
       " [])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_low_variance_columns(dframe=df, columns=df.columns, skip_columns=[], thresh=0.0, autoremove=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Feature Selection\n",
    "Linear correlation scores are typically a value between -1 and 1 with 0 representing no relationship. `For feature selection, we are often interested in a positive score with the larger the positive value`, the larger the relationship, and, more likely, the feature should be selected for modeling. As such the linear correlation can be converted into a correlation statistic with only positive values.\n",
    "\n",
    "The scikit-learn machine library provides an implementation of the correlation statistic in the [f_regression()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html) function. This function can be used in a feature selection strategy, such as selecting the top k most relevant features (largest values) via the [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# Feature selection\n",
    "def select_features(X_train, y_train, X_test, score_func):\n",
    "    \n",
    "    # Configure to select all features\n",
    "    fs = SelectKBest(score_func=score_func, k='all')\n",
    "    \n",
    "    # Learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    \n",
    "    # Transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    \n",
    "    # Transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 00:   231.89\n",
      "Feature 01:   198.71\n",
      "Feature 02:   122.13\n",
      "Feature 03:   101.39\n",
      "Feature 04:    63.96\n",
      "Feature 05:    52.20\n",
      "Feature 06:    45.74\n",
      "Feature 07:    13.95\n",
      "Feature 08:     9.57\n",
      "Feature 09:     5.99\n",
      "Feature 10:     5.96\n",
      "Feature 11:     5.72\n",
      "Feature 12:     5.59\n",
      "Feature 13:     5.36\n",
      "Feature 14:     4.30\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train=X_train, y_train=y_train, X_test=X_test, score_func=f_regression)\n",
    "\n",
    "########## Zrobic dataframe i powiazac scoring z nazwami kolumn, teraz to jest niepowiazane\n",
    "sorted_results = np.sort(fs.scores_)[::-1] # descending order\n",
    "\n",
    "# What are scores for the features\n",
    "for i in range(len(sorted_results[:15])):\n",
    "    print(f'Feature {i:02}: {sorted_results[i]:>8.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar Chart of the Input Features (x) vs. Correlation Feature Importance (y)\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information Feature Selection\n",
    "**Mutual information** from the field of information theory is the application of information gain (typically used in the construction of decision trees) to feature selection. Mutual information is calculated between two variables and measures the reduction in uncertainty for one variable given a known value of the other variable.\n",
    "\n",
    "Mutual information is straightforward when considering the distribution of two discrete (categorical or ordinal) variables, such as categorical input and categorical output data. Nevertheless, it can be adapted for use with numerical input and output data. See [Mutual Information between Discrete and Continuous Data Sets'](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3929353/).\n",
    "\n",
    "The scikit-learn machine learning library provides an implementation of mutual information for feature selection with numeric input and output variables via the [mutual_info_regression()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of mutual information feature selection for numerical input data\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train=X_train, y_train=y_train, X_test=X_test, score_func=f_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 00:   231.89\n",
      "Feature 01:   198.71\n",
      "Feature 02:   122.13\n",
      "Feature 03:   101.39\n",
      "Feature 04:    63.96\n",
      "Feature 05:    52.20\n",
      "Feature 06:    45.74\n",
      "Feature 07:    13.95\n",
      "Feature 08:     9.57\n",
      "Feature 09:     5.99\n",
      "Feature 10:     5.96\n",
      "Feature 11:     5.72\n",
      "Feature 12:     5.59\n",
      "Feature 13:     5.36\n",
      "Feature 14:     4.30\n"
     ]
    }
   ],
   "source": [
    "sorted_results = np.sort(fs.scores_)[::-1] # descending order\n",
    "\n",
    "# What are scores for the features\n",
    "for i in range(len(sorted_results[:15])):\n",
    "    print(f'Feature {i:02}: {sorted_results[i]:>8.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar Chart of the Input Features (x) vs. Correlation Feature Importance (y)\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection using SelectFromModel and LassoCV\n",
    "[Use SelectFromModel meta-transformer along with Lasso to select the best couple of features from the diabetes dataset](https://scikit-learn.org/stable/auto_examples/feature_selection/plot_select_from_model_diabetes.html#sphx-glr-auto-examples-feature-selection-plot-select-from-model-diabetes-py).\n",
    "\n",
    "Since the `L1 norm` promotes sparsity of features we might be interested in selecting only a subset of the most interesting features from the dataset. This example shows how to select two the most interesting features from the diabetes dataset.\n",
    "\n",
    "Diabetes dataset consists of 10 variables (features) collected from 442 diabetes patients. This example shows how to use SelectFromModel and LassoCv to find the best two features predicting disease progression after one year from the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "feature_names = diabetes.feature_names\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decide on the importance of the features we are going to use `LassoCV` estimator. The features with the highest absolute `coef_` value are considered the most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.49684455 235.99640534 521.73854261 321.06689245 569.4426838\n",
      " 302.45627915   0.         143.6995665  669.92633112  66.83430445]\n"
     ]
    }
   ],
   "source": [
    "clf = LassoCV().fit(X, y)\n",
    "importance = np.abs(clf.coef_)\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to select the two features which are the most important. `SelectFromModel()` allows for setting the threshold. Only the features with the `coef_` higher than the threshold will remain. Here, we want to set the threshold slightly above the third highest `coef_` calculated by `LassoCV()` from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['s5' 's1']\n"
     ]
    }
   ],
   "source": [
    "idx_third = importance.argsort()[-3]\n",
    "threshold = importance[idx_third] + 0.01\n",
    "\n",
    "idx_features = (-importance).argsort()[:2]\n",
    "name_features = np.array(feature_names)[idx_features]\n",
    "print('Selected features: {}'.format(name_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm = SelectFromModel(clf, threshold=threshold)\n",
    "sfm.fit(X, y)\n",
    "X_transform = sfm.transform(X)\n",
    "\n",
    "n_features = sfm.transform(X).shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the selected two features from the data\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "plt.title(\n",
    "    \"Features from diabets using SelectFromModel with \"\n",
    "    \"threshold {sfm.threshold:.3f}\")\n",
    "feature1 = X_transform[:, 0]\n",
    "feature2 = X_transform[:, 1]\n",
    "plt.plot(feature1, feature2, 'r.')\n",
    "plt.xlabel(\"First feature: {}\".format(name_features[0]))\n",
    "plt.ylabel(\"Second feature: {}\".format(name_features[1]))\n",
    "plt.ylim([np.min(feature2), np.max(feature2)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importances with forests of trees\n",
    "[This example](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html#sphx-glr-auto-examples-ensemble-plot-forest-importances-py) shows the use of forests of trees to evaluate the importance of features on an artificial classification task. The red bars are the impurity-based feature importances of the forest, along with their inter-trees variability.\n",
    "\n",
    "As expected, the plot suggests that 3 features are informative, while the remaining are not.\n",
    "\n",
    "**Warning:** impurity-based feature importances can be misleading for high cardinality features (many unique values). See [sklearn.inspection.permutation_importance](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance) as an alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a classification task using 3 informative features\n",
    "X, y = make_classification(n_samples=1000,\n",
    "                           n_features=10,\n",
    "                           n_informative=3,\n",
    "                           n_redundant=0,\n",
    "                           n_repeated=0,\n",
    "                           n_classes=2,\n",
    "                           random_state=0,\n",
    "                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a forest and compute the impurity-based feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 1 (0.295902)\n",
      "2. feature 2 (0.208351)\n",
      "3. feature 0 (0.177632)\n",
      "4. feature 3 (0.047121)\n",
      "5. feature 6 (0.046303)\n",
      "6. feature 8 (0.046013)\n",
      "7. feature 7 (0.045575)\n",
      "8. feature 4 (0.044614)\n",
      "9. feature 9 (0.044577)\n",
      "10. feature 5 (0.043912)\n"
     ]
    }
   ],
   "source": [
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAHiCAYAAAAatlGFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfnUlEQVR4nO3de7Ckd13n8c+XCeES5JqRhSRDAsRLUAv0EFQEpyRAEE0oC4qwi4LLbsQlKy6iolKAcV0FFd0t40oWsrIiRAhKzWo0sELwwoIzgSgmEJmES2ZEEpIIcjFhyHf/6Ee382Mm05M55/TJnNer6tR0P5fu7zMnl/d5ztPd1d0BAAD+v7ssewAAANhoRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQywAZUVT9dVa9d9hwAm1V5n2TgSFNVH0vywCRfnlv8Nd39d4f5mP+uu//P4U1351NVr0jy8O5+9rJnAVgvziQDR6rv7e57zX3d4UBeDVV11DKf/466s84NcLhEMrBpVNV9qup1VfXJqtpbVf+5qrZM6x5WVe+sqhuq6tNV9TtVdd9p3W8n2Zbkf1fV56rqJ6pqe1XtGR7/Y1V12nT7FVV1UVW9oao+m+S5t/f8+5n1FVX1hun2iVXVVfWDVXVtVd1UVc+vqkdX1V9X1T9U1a/P7fvcqvqLqvr1qvpMVX24qp4wt/7BVbWjqm6sqt1V9e+H552f+/lJfjrJM6dj/6tpux+sqg9V1T9W1TVV9UNzj7G9qvZU1Y9V1XXT8f7g3Pp7VNWvVNXHp/n+vKruMa371qp6z3RMf1VV24fjumZ6zo9W1b85pH8AAA6BMwTAZvJbSa5L8vAkxyT5gyTXJnlNkkryC0n+NMm9k7w1ySuS/Gh3f39VPS5zl1vMx9vtODPJM5L8QJK7JXnj7Tz/Ih6T5OQkj0+yI8kfJzktyV2TfKCq3tLd757b9qIkxyb5viS/V1UndfeNSS5M8jdJHpzk65K8o6qu7u53HmDuY/OVl1tcl+R7klwzzfNHVbWzu98/rf9XSe6T5LgkT0xyUVW9rbtvSvLLSR6R5NuT/P00661VdVySP0zy/dOxPSHJW6vq65J8Icl/S/Lo7r6qqh6U5P4L/r0BHDJnkoEj1dums5H/UFVvq6oHJvnuzKL38919XZJfTXJWknT37u5+R3ff3N3XJ3l1ku88zBn+b3e/rbtvzSy8D/j8C/q57v6n7n57ks8neVN3X9fde5P8WZJHzW17XZJf6+4vdffvJrkqyVOr6oQkj03yk9NjXZ7ktZkF8VfM3d1f3N8g3f2H3X11z7w7yduTPG5uky8lOXd6/ouTfC7J11bVXZL82yQv7O693f3l7n5Pd9+c5NlJLu7ui6fnfkeSXdPfW5LcmuQbquoe3f3J7r7iEP7uAA6JM8nAkepp8y+yq6pTMzvj+smq+ufFd8nsTG6miP6vmYXeV03rbjrMGa6du/2Q23v+BX1q7vYX93P/XnP39/ZtX5n98czOHD84yY3d/Y/DupUDzL1fVfWUJC9P8jWZHcc9k3xwbpMbunvf3P0vTPMdm+TuSa7ez8M+JMkzqup755bdNcm7uvvzVfXMJC9O8rqq+oskP9bdHz7YrAB3hDPJwGZxbZKbkxzb3fedvu7d3Y+Y1v+XJJ3kG7v73pmd1ay5/ce3Avp8ZmGYJJmuLd46bDO/z8Gef7UdV3M1ntk11X83fd2/qr5qWLf3AHN/xf2qultml6P8cpIHdvd9k1yc2/59Hcink/xTkoftZ921SX577u/nvt19THf/YpJ09yXd/cQkD0ry4ST/Y4HnA7hDRDKwKXT3JzO7JOBXqureVXWX6cV6/3xJxVdldknAZ6ZrY398eIhPJXno3P2/TXL3qnpqVd01yUszu373jj7/avvqJD9SVXetqmck+frMLmW4Nsl7kvxCVd29qr4pyfOSvOF2HutTSU6cLpVIkqMzO9brk+ybzio/aZGhpktPLkjy6ukFhFuq6tum8H5Dku+tqidPy+8+vQjw+Kp6YFWdWVXHZPbDxucyu/wCYE2IZGAz+YHMAu/KzC6luCizs5JJ8rNJvjnJZzJ78djvDfv+QpKXTtc4v7i7P5PkP2R2Pe/ezM4s78ntu73nX23vy+xFfp9O8vNJnt7dN0zrnpXkxMzOKv9+kpcf5P2f3zL9eUNVvX+6VONHkrw5s+P415m9kHBRL87s0oydSW5M8sokd5kC/szM3k3j+szOLP94Zv+vukuSF00z35jZ9eI/fAjPCXBIfJgIwBGmqp6b2TtxfMeyZwG4s3ImGQAABiIZAAAGLrcAAICBM8kAADAQyQAAMNhwn7h37LHH9oknnrjsMQAAOMJddtlln+7u8YOgkmzASD7xxBOza9euZY8BAMARrqo+fqB1C11uUVWnV9VVVbW7ql6yn/XPr6oPVtXlVfXnVXXKtPzEqvritPzyqvrNO34YAACwPg56JrmqtiQ5L8kTM/s0qZ1VtaO7r5zb7I3d/ZvT9mckeXWS06d1V3f3I1d1agAAWEOLnEk+Ncnu7r6mu29JcmFmHxv6L7r7s3N3j0nifeUAALjTWiSSj0ty7dz9PdOy26iqF1TV1UleleRH5ladVFUfqKp3V9XjDmtaAABYB6v2FnDdfV53PyzJTyZ56bT4k0m2dfejkrwoyRur6t7jvlV1dlXtqqpd119//WqNBAAAd8gikbw3yQlz94+flh3IhUmeliTdfXN33zDdvizJ1Um+Ztyhu8/v7pXuXtm6db/vwgEAAOtmkUjemeTkqjqpqo5OclaSHfMbVNXJc3efmuQj0/Kt0wv/UlUPTXJykmtWY3AAAFgrB313i+7eV1XnJLkkyZYkF3T3FVV1bpJd3b0jyTlVdVqSLyW5Kclzpt0fn+TcqvpSkluTPL+7b1yLAwEAgNVS3RvrjShWVlbah4kAALDWquqy7l7Z37pVe+EeAAAcKUQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADETykm3fvj3bt29f9hgAAMwRyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADBYKJKr6vSquqqqdlfVS/az/vlV9cGquryq/ryqTplb91PTfldV1ZNXc3gAAFgLB43kqtqS5LwkT0lySpJnzUfw5I3d/Y3d/cgkr0ry6mnfU5KcleQRSU5P8hvT4wEAwIa1yJnkU5Ps7u5ruvuWJBcmOXN+g+7+7NzdY5L0dPvMJBd2983d/dEku6fHAwCADeuoBbY5Lsm1c/f3JHnMuFFVvSDJi5IcneS75vZ977DvcfvZ9+wkZyfJtm3bFpkbAADWzKq9cK+7z+vuhyX5ySQvPcR9z+/ule5e2bp162qNBAAAd8gikbw3yQlz94+flh3IhUmedgf3BQCApVskkncmObmqTqqqozN7Id6O+Q2q6uS5u09N8pHp9o4kZ1XV3arqpCQnJ/nLwx8bAADWzkGvSe7ufVV1TpJLkmxJckF3X1FV5ybZ1d07kpxTVacl+VKSm5I8Z9r3iqp6c5Irk+xL8oLu/vIaHQsAAKyK6u6Db7WOVlZWeteuXcse47aq1uyht09/XrpmzzDZYN9nAIBlq6rLuntlf+t84h4AAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMutu+/bt2b59+7LHAAA4IJEMAAADkQwAAAORDAAAA5EMAAADkQwAAAORDAAAA5EMAAADkQwAAAORDAAAA5EMAAADkQwAAAORDAAAA5EMAAADkQwAAAORDAAAA5EMAAADkQwAAAORDAAAA5EMAAADkQwAAAORDAAAA5EMAACDo5Y9wGZ36bIHAADgKyx0JrmqTq+qq6pqd1W9ZD/rX1RVV1bVX1fVn1TVQ+bWfbmqLp++dqzm8AAAsBYOeia5qrYkOS/JE5PsSbKzqnZ095Vzm30gyUp3f6GqfjjJq5I8c1r3xe5+5OqODQAAa2eRM8mnJtnd3dd09y1JLkxy5vwG3f2u7v7CdPe9SY5f3TEBAGD9LBLJxyW5du7+nmnZgTwvyR/N3b97Ve2qqvdW1dMOfUQAAFhfq/rCvap6dpKVJN85t/gh3b23qh6a5J1V9cHuvnrY7+wkZyfJtm3bVnMkAAA4ZIucSd6b5IS5+8dPy26jqk5L8jNJzujum/95eXfvnf68JrM3c3jUuG93n9/dK929snXr1kM6AAAAWG2LRPLOJCdX1UlVdXSSs5Lc5l0qqupRSV6TWSBfN7f8flV1t+n2sUkem2T+BX8AALDhHPRyi+7eV1XnJLkkyZYkF3T3FVV1bpJd3b0jyS8luVeSt1RVknyiu89I8vVJXlNVt2YW5L84vCsGAABsOAtdk9zdFye5eFj2srnbpx1gv/ck+cbDGRAAANabj6UGAICBSAYAgIFIBgCAgUgGAICBSAYAgIFIBgCAgUgGAICBSAYAgIFIBgCAgUiGdbB9+/Zs37592WMAAAsSyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADA4atkDsEFV3fmfo3ttHx8AOGI5kwwAAAORDAAAA5EMAAADkQwAAAORDAAAg4UiuapOr6qrqmp3Vb1kP+tfVFVXVtVfV9WfVNVD5tY9p6o+Mn09ZzWHBwCAtXDQSK6qLUnOS/KUJKckeVZVnTJs9oEkK939TUkuSvKqad/7J3l5ksckOTXJy6vqfqs3PgAArL5FziSfmmR3d1/T3bckuTDJmfMbdPe7uvsL0933Jjl+uv3kJO/o7hu7+6Yk70hy+uqMDgAAa2ORSD4uybVz9/dMyw7keUn+6A7uCwAAS7eqn7hXVc9OspLkOw9xv7OTnJ0k27ZtW82RAADgkC1yJnlvkhPm7h8/LbuNqjotyc8kOaO7bz6Ufbv7/O5e6e6VrVu3Ljo7AACsiUUieWeSk6vqpKo6OslZSXbMb1BVj0rymswC+bq5VZckeVJV3W96wd6TpmUAALBhHfRyi+7eV1XnZBa3W5Jc0N1XVNW5SXZ1944kv5TkXkneUlVJ8onuPqO7b6yqn8sstJPk3O6+cU2OBAAAVslC1yR398VJLh6WvWzu9mm3s+8FSS64owMCAMB684l7AAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwOGrZA8CGUXXnfo7utXtsANhknEkGAICBSAYAgIFIBgCAgUgGAICBSAYAgIFIBgCAgUgGAICBSAYAgIFIBgCAgUgGAICBSAYAgIFIBgCAgUgGAICBSAYAgIFIBgCAgUgGAICBSAYAgIFIBgCAgUgGAICBSAYAgIFIBgCAgUgGAICBSAYAgIFIBgCAgUgGAICBSAYAgIFIBgCAgUgGAICBSAYAgMFCkVxVp1fVVVW1u6pesp/1j6+q91fVvqp6+rDuy1V1+fS1Y7UGBwCAtXLUwTaoqi1JzkvyxCR7kuysqh3dfeXcZp9I8twkL97PQ3yxux95+KMCAMD6OGgkJzk1ye7uviZJqurCJGcm+ZdI7u6PTetuXYMZAQBgXS1yucVxSa6du79nWraou1fVrqp6b1U97VCGAwCAZVjkTPLhekh3762qhyZ5Z1V9sLuvnt+gqs5OcnaSbNu2bR1GAgCAA1vkTPLeJCfM3T9+WraQ7t47/XlNkkuTPGo/25zf3SvdvbJ169ZFHxoAANbEIpG8M8nJVXVSVR2d5KwkC71LRVXdr6ruNt0+NsljM3ctMwAAbEQHjeTu3pfknCSXJPlQkjd39xVVdW5VnZEkVfXoqtqT5BlJXlNVV0y7f32SXVX1V0neleQXh3fFAACADWeha5K7++IkFw/LXjZ3e2dml2GM+70nyTce5owAALCufOIeAAAMRDIAAAzW4y3g4DYuXfYAAAAH4UwyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAyOWvYAsBlcuuwBAIBD4kwyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADEQyAAAMRDIAAAwWiuSqOr2qrqqq3VX1kv2sf3xVvb+q9lXV04d1z6mqj0xfz1mtwQEAYK0cNJKrakuS85I8JckpSZ5VVacMm30iyXOTvHHY9/5JXp7kMUlOTfLyqrrf4Y8NAABrZ5Ezyacm2d3d13T3LUkuTHLm/Abd/bHu/usktw77PjnJO7r7xu6+Kck7kpy+CnMDAMCaWSSSj0ty7dz9PdOyRSy0b1WdXVW7qmrX9ddfv+BDAwDA2tgQL9zr7vO7e6W7V7Zu3brscQAA2OQWieS9SU6Yu3/8tGwRh7MvAAAsxSKRvDPJyVV1UlUdneSsJDsWfPxLkjypqu43vWDvSdMyAADYsA4ayd29L8k5mcXth5K8ubuvqKpzq+qMJKmqR1fVniTPSPKaqrpi2vfGJD+XWWjvTHLutAwAADas6u5lz3AbKysrvWvXrmWPcVtVy57g8B3q99kx3/lssH+XAWCjq6rLuntlf+s2xAv3AABgIxHJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQycCa2L59e7Zv377sMQDgDhHJAAAwEMkAq2Qznj13zByJfI9JRDIAcDsEI5uVSAYA2OT8MPSVRDIAAAxEMgAADEQyAAAMRDIAAAxEMgAADBaK5Ko6vaquqqrdVfWS/ay/W1X97rT+fVV14rT8xKr6YlVdPn395irPDwAAq+6og21QVVuSnJfkiUn2JNlZVTu6+8q5zZ6X5KbufnhVnZXklUmeOa27ursfubpjAwDA2lnkTPKpSXZ39zXdfUuSC5OcOWxzZpLXT7cvSvKEqqrVGxMAANbPIpF8XJJr5+7vmZbtd5vu3pfkM0keMK07qao+UFXvrqrHHea8AACw5g56ucVh+mSSbd19Q1V9S5K3VdUjuvuz8xtV1dlJzk6Sbdu2rfFIAABw+xY5k7w3yQlz94+flu13m6o6Ksl9ktzQ3Td39w1J0t2XJbk6ydeMT9Dd53f3SnevbN269dCPAgAAVtEikbwzyclVdVJVHZ3krCQ7hm12JHnOdPvpSd7Z3V1VW6cX/qWqHprk5CTXrM7oAACwNg56uUV376uqc5JckmRLkgu6+4qqOjfJru7ekeR1SX67qnYnuTGzkE6Sxyc5t6q+lOTWJM/v7hvX4kCAO2A9Xl+7ls/RvXaPDcCmttA1yd19cZKLh2Uvm7v9T0mesZ/93prkrYc5I8DqWK833dlIPxhsxmMGWAVr/cI9AFhffjAAVoFIBoA7uzv7pVPJxvwtyUY7ZtaVSAYAuDPwg8G6WuTdLQAAYFMRyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwOGrZAwBHpkuXPcASXLrsAZbg0mUPALBGnEkGAICBM8kAcAguXfYAwLoQyQDAAV267AFgSUQyAMCcS5c9wBJcuuwBNiDXJAMAwEAkAwDAQCQDAMBAJAMAwEAkAwDAQCQDAMBAJAMAwEAkAwDAQCQDAMBAJAMAwEAkAwDAQCQDAMBAJAMAwEAkAwDAQCQDAMBAJAMAwEAkAwDAQCQDAMBAJAMAwEAkAwDAQCQDAMBAJAMAwEAkAwDAQCQDAMBAJAMAwEAkAwDAQCQDAMBAJAMAwEAkAwDAQCQDAMBAJAMAwEAkAwDAYKFIrqrTq+qqqtpdVS/Zz/q7VdXvTuvfV1Unzq37qWn5VVX15FWcHQAA1sRBI7mqtiQ5L8lTkpyS5FlVdcqw2fOS3NTdD0/yq0leOe17SpKzkjwiyelJfmN6PAAA2LAWOZN8apLd3X1Nd9+S5MIkZw7bnJnk9dPti5I8oapqWn5hd9/c3R9Nsnt6PAAA2LAWieTjklw7d3/PtGy/23T3viSfSfKABfcFAIAN5ahlD5AkVXV2krOnu5+rqquWOc8SHJvk02v6DFVr+vB3gGNebRvveBPHvPoc80ax2Y7Zf7PXgmPeCB5yoBWLRPLeJCfM3T9+Wra/bfZU1VFJ7pPkhgX3TXefn+T8BWY5IlXVru5eWfYc68kxbw6OeXNwzEe+zXa8iWNmscstdiY5uapOqqqjM3sh3o5hmx1JnjPdfnqSd3Z3T8vPmt794qQkJyf5y9UZHQAA1sZBzyR3976qOifJJUm2JLmgu6+oqnOT7OruHUlel+S3q2p3khszC+lM2705yZVJ9iV5QXd/eY2OBQAAVsVC1yR398VJLh6WvWzu9j8lecYB9v35JD9/GDNuBpvxUhPHvDk45s3BMR/5NtvxJo5506vZVREAAMA/87HUAAAwEMlLVFUXVNV1VfU3y55lvVTVCVX1rqq6sqquqKoXLnum9XCwj3Y/0lTV3avqL6vqr6bv888ue6a1VlX3raqLqurDVfWhqvq2Zc+01qrqP03f37+pqjdV1d2XPdNaqqqvrarL574+W1U/uuy51kNVbamqD1TVHyx7lvVQVS+c/rm+YhN9jz9WVR+c/tnetex5NgKXWyxRVT0+yeeS/K/u/oZlz7MequpBSR7U3e+vqq9KclmSp3X3lUsebc1MH8X+t0memNkH6uxM8qwj/JgryTHd/bmqumuSP0/ywu5+75JHWzNV9fokf9bdr53eCeie3f0PSx5rzVTVcZl9X0/p7i9OL9K+uLt/a7mTrY/p3+u9SR7T3R9f9jxrrapelGQlyb27+3uWPc9aqqpvyOzThU9NckuSP07y/O7evdTB1lhVfSzJSnev7fsk34k4k7xE3f2nmb0byKbR3Z/s7vdPt/8xyYdy5H8K4yIf7X5E6ZnPTXfvOn0dsT+RV9V9kjw+s3f6SXffciQH8pyjktxjen/8eyb5uyXPs56ekOTqTRLIxyd5apLXLnuWdfL1Sd7X3V+YPkX43Um+b8kzsQQimaWpqhOTPCrJ+5Y8ylrblB/PPv169vIk1yV5R3cfyd/nk5Jcn+R/Tr+Sfm1VHbPsodZSd+9N8stJPpHkk0k+091vX+5U6+qsJG9a9hDr5NeS/ESSW5c8x3r5mySPq6oHVNU9k3x3bvvBaEeqTvL2qrps+iTkTU8ksxRVda8kb03yo9392WXPw+rr7i939yMz+6TNU6dfYR6pjkryzUn+e3c/KsnnkxzR155X1f0y+43ISUkenOSYqnr2cqdaH9PlNGckecuyZ1lrVfU9Sa7r7suWPct66e4PJXllkrdndqnF5Uk2w2c8fEd3f3OSpyR5wXRJ6KYmkll30zWqb03yO939e8ueZx0s9PHsR6rpsoN3JTl9yaOspT1J9sydLb8os2g+kp2W5KPdfX13fynJ7yX59iXPtF6ekuT93f2pZQ+yDh6b5IzpetULk3xXVb1huSOtve5+XXd/S3c/PslNmb2u5Ig2/XYo3X1dkt/P7FLBTU0ks66mF3S9LsmHuvvVy55nnSzy0e5HlKraWlX3nW7fI7MXLX54qUOtoe7++yTXVtXXTouekNknjR7JPpHkW6vqntO/10/I7DUGm8Gzskkutejun+ru47v7xMz+2/XO7j7if2NQVV89/bkts+uR37jcidZWVR0zvZg+06ViT8rsspNNbaFP3GNtVNWbkmxPcmxV7Uny8u5+3XKnWnOPTfL9ST44Xa+aJD89farjEelAH+2+5LHW2oOSvH56B4C7JHlzdx/pbx31H5P8zvSD0DVJfnDJ86yp7n5fVV2U5P1J9iX5QDbBp3VNAfHEJD+07FlYU2+tqgck+VKSF2yCF+I+MMnvz37ezVFJ3tjdf7zckZbPW8ABAMDA5RYAADAQyQAAMBDJAAAwEMkAADAQyQAAMBDJAAAwEMkAADAQyQAAMPh/q0DqP/a1bQUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the impurity-based feature importances of the forest\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling With Selected Features\n",
    "A robust approach is to evaluate models using different feature selection methods (and numbers of features) and select the method that results in a model with the best performance. Linear regression is a good model for testing feature selection methods as it can perform better if irrelevant features are removed from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Built Using All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.086\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of a model using all input features\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load the dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# Evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Built Using Correlation Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.740\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of a model using 10 features chosen with correlation\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=f_regression, k=10)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# Load the dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# Feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "# Fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_fs, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "\n",
    "# Evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we see that the model achieved an error score of about 2.7, which is much larger than the baseline model that used all features and achieved an MAE of 0.086.\n",
    "\n",
    "This suggests that although the method has a strong idea of what features to select, building a model from these features alone does not result in a more skillful model. This could be because features that are important to the target are being left out, meaning that the method is being deceived about what is important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Built Using Mutual Information Features\n",
    "Running the example fits the model on the 88 top selected features chosen using mutual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.084\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of a model using 88 features chosen with mutual information\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=mutual_info_regression, k=88)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# Load the dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# Feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "# Fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_fs, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "\n",
    "# Evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can see a further reduction in error as compared to the correlation statistic, in this case, achieving a MAE of about 0.084."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the Number of Selected Features\n",
    "In the previous example, we selected 88 features, but how do we know that is a good or best number of features to select?\n",
    "\n",
    "Instead of guessing, we can systematically test a range of different numbers of selected features and discover which results in the best performing model. This is called a grid search, where the k argument to the SelectKBest class can be tuned.\n",
    "\n",
    "It is a good practice to evaluate model configurations on regression tasks using repeated stratified k-fold cross-validation. We will use three repeats of 10-fold cross-validation via the RepeatedKFold class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a Pipeline that correctly prepares the feature selection transform on the training set and applies it to the train set and test set for each fold of the cross-validation.\n",
    "\n",
    "In this case, we will use the mutual information statistical method for selecting features. \n",
    "\n",
    "We can then define the grid of values to evaluate as 80 to 100.\n",
    "\n",
    "Note that the grid is a dictionary mapping of parameter-to-values to search, and given that we are using a Pipeline, we can access the SelectKBest object via the name we gave it ‘sel‘ and then the parameter name ‘k‘ separated by two underscores, or ‘sel__k‘.\n",
    "\n",
    "In this case, we will evaluate models using the negative mean absolute error (neg_mean_absolute_error). It is negative because the scikit-learn requires the score to be maximized, so the MAE is made negative, meaning scores scale from -infinity to 0 (best)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE: -0.010\n",
      "Best Config: {'sel__k': 81}\n",
      ">-50.101 with: {'sel__k': 80}\n",
      ">-0.010 with: {'sel__k': 81}\n",
      ">-0.010 with: {'sel__k': 82}\n",
      ">-0.010 with: {'sel__k': 83}\n",
      ">-0.010 with: {'sel__k': 84}\n",
      ">-0.010 with: {'sel__k': 85}\n",
      ">-0.010 with: {'sel__k': 86}\n",
      ">-0.010 with: {'sel__k': 87}\n",
      ">-0.010 with: {'sel__k': 88}\n",
      ">-0.010 with: {'sel__k': 89}\n",
      ">-0.010 with: {'sel__k': 90}\n",
      ">-0.011 with: {'sel__k': 91}\n",
      ">-0.011 with: {'sel__k': 92}\n",
      ">-0.011 with: {'sel__k': 93}\n",
      ">-0.011 with: {'sel__k': 94}\n",
      ">-0.011 with: {'sel__k': 95}\n",
      ">-0.011 with: {'sel__k': 96}\n",
      ">-0.011 with: {'sel__k': 97}\n",
      ">-0.011 with: {'sel__k': 98}\n",
      ">-0.011 with: {'sel__k': 99}\n",
      ">-0.011 with: {'sel__k': 100}\n"
     ]
    }
   ],
   "source": [
    "# Compare different numbers of features selected using mutual information\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "\n",
    "# Define the evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Define the pipeline to evaluate\n",
    "model = LinearRegression()\n",
    "fs = SelectKBest(score_func=mutual_info_regression)\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('sel',fs), \n",
    "    ('lr', model),\n",
    "])\n",
    "\n",
    "# Define the grid\n",
    "grid = dict()\n",
    "grid['sel__k'] = [i for i in range(X.shape[1]-20, X.shape[1]+1)]\n",
    "\n",
    "# Define the grid search\n",
    "search = GridSearchCV(pipeline, grid, scoring='neg_mean_squared_error', n_jobs=-1, cv=cv)\n",
    "\n",
    "# Perform the search\n",
    "results = search.fit(X, y)\n",
    "\n",
    "# Summarize best\n",
    "print('Best MAE: %.3f' % results.best_score_)\n",
    "print('Best Config: %s' % results.best_params_)\n",
    "\n",
    "# Summarize all\n",
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example grid searches different numbers of selected features using mutual information statistics, where each modeling pipeline is evaluated using repeated cross-validation.\n",
    "\n",
    "In this case, we can see that the best number of selected features is 81, which achieves a MAE of about 0.01 (ignoring the sign).\n",
    "\n",
    "We might want to see the relationship between the number of selected features and MAE. In this relationship, we may expect that more features result in better performance, to a point.\n",
    "\n",
    "This relationship can be explored by manually evaluating each configuration of k for the SelectKBest from 81 to 100, gathering the sample of MAE scores, and plotting the results using box and whisker plots side by side. The spread and mean of these box plots would be expected to show any interesting relationship between the number of selected features and the MAE of the pipeline.\n",
    "\n",
    "Note that we started the spread of k values at 81 instead of 80 because the distribution of MAE scores for k=80 is dramatically larger than all other values of k considered and it washed out the plot of the results on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">81 -0.082 (0.006)\n",
      ">82 -0.082 (0.006)\n",
      ">83 -0.082 (0.006)\n",
      ">84 -0.082 (0.006)\n",
      ">85 -0.082 (0.006)\n",
      ">86 -0.082 (0.006)\n",
      ">87 -0.082 (0.006)\n",
      ">88 -0.082 (0.006)\n",
      ">89 -0.083 (0.006)\n",
      ">90 -0.083 (0.006)\n",
      ">91 -0.083 (0.006)\n",
      ">92 -0.083 (0.006)\n",
      ">93 -0.083 (0.006)\n",
      ">94 -0.083 (0.006)\n",
      ">95 -0.083 (0.006)\n",
      ">96 -0.083 (0.006)\n",
      ">97 -0.083 (0.006)\n",
      ">98 -0.083 (0.006)\n",
      ">99 -0.083 (0.006)\n",
      ">100 -0.083 (0.006)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare different numbers of features selected using mutual information\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "\n",
    "# Define number of features to evaluate\n",
    "num_features = [i for i in range(X.shape[1]-19, X.shape[1]+1)]\n",
    "\n",
    "# Enumerate each number of features\n",
    "results = list()\n",
    "for k in num_features:\n",
    "    # create pipeline\n",
    "    model = LinearRegression()\n",
    "    fs = SelectKBest(score_func=mutual_info_regression, k=k)\n",
    "    pipeline = Pipeline(steps=[('sel',fs), ('lr', model)])\n",
    "    # evaluate the model\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    results.append(scores)\n",
    "    # summarize the results\n",
    "    print('>%d %.3f (%.3f)' % (k, mean(scores), std(scores)))\n",
    "\n",
    "# Plot model performance for comparison\n",
    "plt.boxplot(results, labels=num_features, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first reports the mean and standard deviation MAE for each number of selected features. Box and whisker plots are created side by side showing the trend of k vs. MAE where the green triangle represents the mean and orange line represents the median of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
